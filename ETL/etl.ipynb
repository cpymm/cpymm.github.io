{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "# <font color = #6b4cde face=\"Verdana\"> **Universities and Gentrification**\n",
    "## <font color = #6b4cde face=\"Verdana\"> **UMD CMSC320 Data Science, Spring 2023** </font>\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Joe Diaz and Connor Pymm** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üôèRUN ME FIRSTüôè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Data Curation** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Datasets\n",
    "\n",
    "In order to perform analysis on colleges and their surrounding regions, we needed to\n",
    "find some subset of colleges, a dataset with characteristics of those colleges on a yearly basis, \n",
    "and then a dataset with characteristics of their nearby geographical areas. again yearly. \n",
    "\n",
    "Initially, we decided to limit our analysis to the top 100 universities in the country \n",
    "according to current US News rankings, under the assumption that more highly ranked universities \n",
    "might have a more significant impact on their respective communities. We used Andy Reiter's\n",
    "‚ÄúU.S. News & World Report Historical Liberal Arts College and University Rankings‚Äù dataset (**citation**).\n",
    "  \n",
    "In order to obtain college characteristics, we discovered that the Department of\n",
    "Education has extensive data available on accredited universities called the College Scorecard, which has\n",
    "a public API for programatically querying data.\n",
    "  \n",
    "In order to obtain characteristics of the region around each university, we needed a dataset that would contain\n",
    "demographic and economic data for defined geographical regions associated with the location of the University.\n",
    "We found that the American Community Survey yearly data from the Census had the housing cost and income data we\n",
    "wanted to analyze, and that its Public Use Microdata API from the census allowed us to programatically request that\n",
    "data for geographical groupings called \"Public Use Microdata Areas,\" which are the smallest geographical entities that\n",
    "the Census collects yearly data from."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract, Transform, and Load\n",
    "\n",
    "Since we queried a *substantial* amount of data from *ridiculously large* datasets,\n",
    "and requesting federal data from the Department of Education and the Census required\n",
    "registration for and usage of API keys, we decided that on top of the source datasets that\n",
    "we were able to download in full, stored in our repository under ETL/source_data, we would\n",
    "create modules for making federal API requests and loading the results into csv files for usage\n",
    "later. \n",
    "  \n",
    "Dataframes that we generated from data that we queried were stored under ETL/generated_data\n",
    "as csv, and then loaded into the notebook when needed, specifically: we built ScorecardData.csv using\n",
    "our scorecard_client.py module, which defines a CollegeScorecardClient object that can be used to query\n",
    "DoE data, given a valid API key, set of desired variables, and set of colleges using IPEDS IDs, we built \n",
    "college_FIPs by combining the university list we got from Reiter with state FIPs data from DoE and county \n",
    "FIPs data by collecting them manually university by university.\n",
    "\n",
    "For the rest of this tutorial, we will be using the data we collected by default, but if you would like to\n",
    "recreate the analysis of this tutorial using a different set of colleges, and thus your own datasets, you can\n",
    "fork this repository and use the modules provided in the ETL/ directory to do so."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Data Processing** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Representation\n",
    "\n",
    "Here, we load the data we have downloaded or generated locally into our\n",
    "notebook for use to use in our analysis. We stored each of our datasets as\n",
    "csv, so they are easily loaded into Pandas Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframes from generated data\n",
    "CollegeScorecard_df_raw = pd.read_csv(\"generated_data/ScorecardData.csv\")\n",
    "fips_df = pd.read_csv(\"generated_data/college_FIPs.csv\")\n",
    "cpi_df = pd.read_csv(\"source_data/cpi_all.csv\").groupby(\"Year\")[\"Value\"].mean()\n",
    "\n",
    "# Join county FIPs codes into College Scorecard dataframe for use later in\n",
    "# associating with Census geographies.\n",
    "scard_df = CollegeScorecard_df_raw.copy()\n",
    "scard_df = pd.merge(scard_df, fips_df[[\"school.name\", \"county_fips\"]], on=\"school.name\", how=\"left\")\n",
    "\n",
    "scard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be more readable, usable\n",
    "scard_df = scard_df.rename(\n",
    "    columns={\n",
    "        \"student.size\": \"size\",\n",
    "        \"cost.tuition.in_state\": \"in_state_tuition\",\n",
    "        \"cost.tuition.out_of_state\": \"out_state_tuition\",\n",
    "        \"cost.avg_net_price.public\": \"public_net_price\",\n",
    "        \"cost.avg_net_price.private\": \"private_net_price\",\n",
    "        \"id\": \"ipeds_id\",\n",
    "        \"school.name\": \"name\",\n",
    "        \"school.carnegie_size_setting\": \"size_setting\",\n",
    "        \"school.zip\": \"zip\",\n",
    "        \"school.state_fips\": \"state_fips\",\n",
    "        \"school.region_id\": \"region_id\",\n",
    "        \"school.locale\": \"locale\",\n",
    "        \"school.ownership\": \"ownership\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Combine public and private net prices into a single net price column, and drop those columns\n",
    "scard_df[\"net_cost\"] = scard_df.apply(lambda row: \n",
    "            row[\"public_net_price\"] if (row[\"ownership\"] == 1) else row[\"private_net_price\"],\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"net_cost_adjusted\"] = scard_df.apply(lambda row: \n",
    "            (row[\"net_cost\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"in_tuition_adjusted\"] = scard_df.apply(lambda row: \n",
    "            (row[\"in_state_tuition\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"out_tuition_adjusted\"] = scard_df.apply(lambda row: \n",
    "            (row[\"out_state_tuition\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df.drop([\"public_net_price\", \"private_net_price\"], axis=1, inplace=True)\n",
    "scard_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
