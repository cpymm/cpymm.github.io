{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "# <font color = #6b4cde face=\"Verdana\"> **Universities and Gentrification**\n",
    "## <font color = #6b4cde face=\"Verdana\"> **UMD CMSC320 Data Science, Spring 2023** </font>\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Joe Diaz and Connor Pymm** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üôèRUN ME FIRSTüôè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Data Curation** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Datasets\n",
    "\n",
    "In order to perform analysis on colleges and their surrounding regions, we needed to\n",
    "find some subset of colleges, a dataset with characteristics of those colleges on a yearly basis, \n",
    "and then a dataset with characteristics of their nearby geographical areas. again yearly. \n",
    "\n",
    "Initially, we decided to limit our analysis to the top 100 universities in the country \n",
    "according to current US News rankings, under the assumption that more highly ranked universities \n",
    "might have a more significant impact on their respective communities. We used Andy Reiter's\n",
    "‚ÄúU.S. News & World Report Historical Liberal Arts College and University Rankings‚Äù dataset (**citation**).\n",
    "  \n",
    "In order to obtain college characteristics, we discovered that the Department of\n",
    "Education has extensive data available on accredited universities called the College Scorecard, which has\n",
    "a public API for programatically querying data.\n",
    "  \n",
    "In order to obtain characteristics of the region around each university, we needed a dataset that would contain\n",
    "demographic and economic data for defined geographical regions associated with the location of the University.\n",
    "We found that the American Community Survey yearly data from the Census had the housing cost and income data we\n",
    "wanted to analyze, and that its Public Use Microdata API from the census allowed us to programatically request that\n",
    "data for geographical groupings called \"Public Use Microdata Areas,\" which are the smallest geographical entities that\n",
    "the Census collects yearly data from."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract, Transform, and Load\n",
    "\n",
    "Since we queried a *substantial* amount of data from *ridiculously large* datasets,\n",
    "and requesting federal data from the Department of Education and the Census required\n",
    "registration for and usage of API keys, we decided that on top of the source datasets that\n",
    "we were able to download in full, stored in our repository under ETL/source_data, we would\n",
    "create modules for making federal API requests and loading the results into csv files for usage\n",
    "later. \n",
    "  \n",
    "Dataframes that we generated from data that we queried were stored under ETL/generated_data\n",
    "as csv, and then loaded into the notebook when needed, specifically: we built ScorecardData.csv using\n",
    "our scorecard_client.py module, which defines a CollegeScorecardClient object that can be used to query\n",
    "DoE data, given a valid API key, set of desired variables, and set of colleges using IPEDS IDs, we built \n",
    "college_FIPs by combining the university list we got from Reiter with state FIPs data from DoE and county \n",
    "FIPs data by collecting them manually university by university.\n",
    "\n",
    "For the rest of this tutorial, we will be using the data we collected by default, but if you would like to\n",
    "recreate the analysis of this tutorial using a different set of colleges, and thus your own datasets, you can\n",
    "fork this repository and use the modules provided in the ETL/ directory to do so."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Data Processing** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Representation\n",
    "\n",
    "Here, we load the data we have downloaded or generated locally into our\n",
    "notebook for use to use in our analysis. We stored each of our datasets as\n",
    "csv, so they are easily loaded into Pandas Dataframes. We will also have to define a few new terms so that the reader can understand what we are talking about:\n",
    "1. **MSA**: The MSA is the metropolitan statistical area in the U.S. Census. It includes 384 census-designated regions in the U.S. with more than 50,000 people in each block. We use this data as a standard for the general region around colleges and as a sort of control variable compared to our more limited and specific PUMA.\n",
    "2. **PUMA**: The PUMAs stands for \"Public Use Microdata Areas\", which is kind of in between a county and a school system in the Census. IT was the smallest readily available geography in the Census dataset that we could convert to using zip codes and tracts, so we use it as our specific locality that we are comparing against our control (MSA). If our hypothesis is correct, these should be more volatile since the prices of colleges should be driving up prices in these localities.\n",
    "3. **Tract**: A Census Tract is a specific section of land, even more specific than the PUMA, that we use to connect the zip codes from the top 100 universities and the MSAs and PUMA's from the Census. They are very finnicky and hard to work with, but we found a U.S. government API that allows us to convert between Zip Codes, Census Tracts, and MSAs, which allowed us to complete our analysis.\n",
    "4. **Zip Code**: You likely already know what a zip code is, but working with Zip Codes was a very difficult challenge in this project since they are maintained by the U.S. Postal Service, not the Census, so neither agency has a standard measurement for localities, hence why we needed to convert from Zip -> Tract -> MSA and PUMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframes from Scorecard generated data\n",
    "scard_df = pd.read_csv(\"ETL/generated_data/ScorecardData.csv\")\n",
    "fips_df = pd.read_csv(\"ETL/generated_data/college_FIPs.csv\")\n",
    "cpi_df = pd.read_csv(\"ETL/source_data/cpi_all.csv\").groupby(\"Year\")[\"Value\"].mean()\n",
    "scard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2009, 2020)\n",
    "msa_path_format = \"ETL/generated_data/MSA{y}.csv\"\n",
    "MSA_frames = [\n",
    "    pd.read_csv(msa_path_format.format(y=yr)).assign(year=yr)\n",
    "    for yr in years\n",
    "]\n",
    "msa_df = pd.concat(MSA_frames)\n",
    "msa_df.columns = [\"name\", \"msa_income\", \"msa_rent\", \"msa\", \"year\"]\n",
    "print(msa_df[\"name\"].unique().shape)\n",
    "msa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2009, 2020)\n",
    "puma_path_format = \"ETL/generated_data/PUMA{y}.csv\"\n",
    "PUMA_frames = [\n",
    "    pd.read_csv(puma_path_format.format(y=yr)).assign(year=yr)\n",
    "    for yr in years\n",
    "]\n",
    "puma_df = pd.concat(PUMA_frames).reset_index(drop=True)\n",
    "puma_df.columns = [\"puma_income\", \"puma_rent\", \"state\", \"puma\", \"year\"]\n",
    "puma_df[\"state\"] = puma_df[\"state\"].astype(\"int\")\n",
    "puma_df[\"puma\"] = puma_df[\"puma\"].astype(\"int\")\n",
    "puma_df[\"year\"] = puma_df[\"year\"].astype(\"int\")\n",
    "\n",
    "print(puma_df[\"puma\"].unique().shape)\n",
    "puma_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Reshaping\n",
    "\n",
    "The data that we have still uses the variable names and formatting of our\n",
    "original sources, and those variable names are unweildy and not ideal for usage\n",
    "in analysis later, so we rename our columns to be more human readable and\n",
    "developer friendly. Additionally, cost data in our sources does not account for\n",
    "inflation, so we should use an all-consumers/all-goods CPI to transform our dollar\n",
    "values to a standard value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be more readable, usable\n",
    "scard_df = scard_df.rename(\n",
    "    columns={\n",
    "        \"student.size\": \"size\",\n",
    "        \"cost.tuition.in_state\": \"in_state_tuition\",\n",
    "        \"cost.tuition.out_of_state\": \"out_state_tuition\",\n",
    "        \"cost.avg_net_price.public\": \"public_net_price\",\n",
    "        \"cost.avg_net_price.private\": \"private_net_price\",\n",
    "        \"id\": \"id\",\n",
    "        \"school.name\": \"name\",\n",
    "        \"school.carnegie_size_setting\": \"size_setting\",\n",
    "        \"school.zip\": \"zip\",\n",
    "        \"school.state_fips\": \"state_fips\",\n",
    "        \"school.region_id\": \"region_id\",\n",
    "        \"school.locale\": \"locale\",\n",
    "        \"school.ownership\": \"ownership\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Join county FIPs codes into College Scorecard dataframe for use later in\n",
    "# associating with Census geographies.\n",
    "scard_df = pd.merge(\n",
    "    scard_df, \n",
    "    fips_df[[\"id\", \"county\", \"cbsa\", \"puma\"]], \n",
    "    on=\"id\", how=\"left\").drop_duplicates()\n",
    "print(scard_df)\n",
    "\n",
    "# Combine public and private net prices into a single net price column, and drop those columns\n",
    "scard_df[\"net_cost\"] = scard_df.apply(lambda row: \n",
    "            row[\"public_net_price\"] if (row[\"ownership\"] == 1) else row[\"private_net_price\"],\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"net_cost_adjusted\"] = scard_df.apply(lambda row: \n",
    "            (row[\"net_cost\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"in_tuition_adjusted\"] = scard_df.apply(lambda row: \n",
    "            (row[\"in_state_tuition\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"out_tuition_adjusted\"] = scard_df.apply(lambda row: \n",
    "            (row[\"out_state_tuition\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"non_tuition_expenses_adj\"] = scard_df.apply(lambda row: \n",
    "            row[\"net_cost_adjusted\"] - row[\"in_tuition_adjusted\"],\n",
    "        axis=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "scard_df[\"state_fips\"] = scard_df[\"state_fips\"].astype(int)\n",
    "scard_df[\"year\"] = scard_df[\"year\"].astype(int)\n",
    "scard_df.drop([\"public_net_price\", \"private_net_price\"], axis=1, inplace=True)\n",
    "scard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale_map = {\n",
    "    11:\t\"City: Large\",\n",
    "    12:\t\"City: Midsize\",\n",
    "    13:\t\"City: Small\",\n",
    "    21:\t\"Suburb: Large\",\n",
    "    22:\t\"Suburb: Midsize\",\n",
    "    23:\t\"Suburb: Small\",\n",
    "    31:\t\"Town: Fringe\",\n",
    "    32:\t\"Town: Distant\",\n",
    "    33:\t\"Town: Remote\",\n",
    "    41:\t\"Rural: Fringe\",\n",
    "    42:\t\"Rural: Distant\",\n",
    "    43:\t\"Rural: Remote\"\n",
    "}\n",
    "ownership_map = {\n",
    "    1:\t\"Public\",\n",
    "    2:\t\"Private nonprofit\",\n",
    "    3:\t\"Private for-profit\"\n",
    "}\n",
    "region_map = {\n",
    "    0:\t\"U.S. Service Schools\",\n",
    "    1:\t\"New England\",\n",
    "    2:\t\"Mid East\",\n",
    "    3:\t\"Great Lakes\",\n",
    "    4:\t\"Plains\",\n",
    "    5:\t\"Southeast\",\n",
    "    6:\t\"Southwest\",\n",
    "    7:\t\"Rocky Mountains\",\n",
    "    8:\t\"Far West\",\n",
    "    9:\t\"Outlying Areas\"\n",
    "}\n",
    "\n",
    "scard_df[\"region\"] = scard_df.apply(lambda row: \n",
    "            region_map[row[\"region_id\"]],\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"ownership\"] = scard_df.apply(lambda row: \n",
    "            ownership_map[row[\"ownership\"]],\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"locale\"] = scard_df.apply(lambda row: \n",
    "            locale_map[row[\"locale\"]],\n",
    "        axis=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that some rows do not have cost data associated with them, thus they are missing data.\n",
    "Since we will use this cost data later in our analysis, we need to either interpolate the missing data\n",
    "or drop the invalid rows. Here, we experiment with dropping rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_clipped = scard_df.dropna(subset=[\"net_cost\", \"in_state_tuition\", \"out_state_tuition\"]).copy()\n",
    "#print(scard_clipped[\"name\"].unique().shape)\n",
    "#print(scard_clipped.to_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems as if the clipped dataframe after dropping null cost data is just the data after 2009.\n",
    "To verify that this is true, I try querying the original dataset purely by restricting the years.\n",
    "If there is complete cost data from 2009 to 2020, then the resulting dataframe should be equal to the\n",
    "dataframe resulting from dropping null data. Run the next code cell to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_clipped_year = scard_df[scard_df[\"year\"] >= 2009].copy()\n",
    "scard_clipped_year.equals(scard_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_df[\"msa\"] = msa_df[\"msa\"].str.replace(\"]\", \"\").astype(int)\n",
    "msa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_clipped_geo = scard_clipped.dropna(subset=[\"cbsa\", \"puma\"]).copy()\n",
    "scard_clipped_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_clipped_geo[\"puma\"] = scard_clipped_geo[\"puma\"].astype(int)\n",
    "scard_clipped_geo[\"cbsa\"] = scard_clipped_geo[\"cbsa\"].astype(int)\n",
    "print(scard_clipped_geo[\"puma\"].unique().shape)\n",
    "scard_clipped_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_df = scard_clipped_geo\n",
    "scard_df = pd.merge(scard_df, puma_df, left_on=[\"puma\", \"year\"], right_on=[\"puma\", \"year\"], how=\"inner\")\n",
    "scard_df[\"name\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_df = pd.merge(scard_df, msa_df, left_on=[\"cbsa\", \"year\"], right_on=[\"msa\", \"year\"], how=\"left\")\n",
    "scard_df[\"name_y\"].unique().shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Exploratory Analysis and Data Visualization** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be analyzing different components of our dataset graphically to display relationships present within it. For example, in this next block, we look at a violin plot of the net cost of every university and how it changes every year. Since the purpose of a violin plot is to visualize a distribute of data, we are able to see the increasing volatility in the net cost of university as time goes on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Violin(\n",
    "        x=scard_df['year'], \n",
    "        y=scard_df['net_cost'],\n",
    "        box_visible=True,\n",
    "        meanline_visible=True\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Violin(\n",
    "        x=scard_df['year'], \n",
    "        y=scard_df['in_state_tuition'],\n",
    "        box_visible=True,\n",
    "        meanline_visible=True\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Violin(\n",
    "        x=scard_df['year'], \n",
    "        y=scard_df['out_state_tuition'],\n",
    "        box_visible=True,\n",
    "        meanline_visible=True\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(scard_df, x=\"year\", y=\"in_state_tuition\", facet_col=\"ownership\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(scard_df, x=\"year\", y=\"in_tuition_adjusted\", facet_col=\"ownership\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(scard_df, x=\"year\", y=\"out_tuition_adjusted\", facet_col=\"ownership\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.add_trace(\n",
    "    go.Violin(x=msa_df[\"year\"], \n",
    "              y=msa_df[\"msa_income\"], \n",
    "              box_visible=True,\n",
    "              meanline_visible=True\n",
    "             ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Violin(x=msa_df[\"year\"], \n",
    "              y=msa_df[\"msa_rent\"], \n",
    "              box_visible=True,\n",
    "              meanline_visible=True\n",
    "             ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Median Household Income\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Median Monthly Rent \", row=1, col=2)\n",
    "fig.update_layout(title_text=\"Household Income vs. Monthly Rent Over Time for MSA Adjusted for Inflation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.add_trace(\n",
    "    go.Violin(x=puma_df[\"year\"], \n",
    "              y=puma_df[\"puma_income\"], \n",
    "              box_visible=True,\n",
    "              meanline_visible=True\n",
    "             ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Violin(x=puma_df[\"year\"], \n",
    "              y=puma_df[\"puma_rent\"], \n",
    "              box_visible=True,\n",
    "              meanline_visible=True\n",
    "             ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Median Household Income\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Median Monthly Rent\", row=1, col=2)\n",
    "fig.update_layout(title_text=\"Household Income vs. Monthly Rent Over Time for PUMA\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_df[\"msa_income_adj\"] = msa_df.apply(lambda row: \n",
    "            (row[\"msa_income\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "msa_df[\"msa_rent_adj\"] = msa_df.apply(lambda row: \n",
    "            (row[\"msa_rent\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"msa_income_adj\"] = scard_df.apply(lambda row: \n",
    "            (row[\"msa_income\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"msa_rent_adj\"] = scard_df.apply(lambda row: \n",
    "            (row[\"msa_rent\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"msa_rent_adj_ytd\"] = scard_df.apply(lambda row: \n",
    "            (row[\"msa_rent\"]/cpi_df.at[row[\"year\"]]) * 100 * 12,\n",
    "        axis=1\n",
    ")\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.add_trace(\n",
    "    go.Violin(x=msa_df[\"year\"], \n",
    "              y=msa_df[\"msa_income_adj\"], \n",
    "              box_visible=True,\n",
    "              meanline_visible=True\n",
    "             ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Violin(x=msa_df[\"year\"], \n",
    "              y=msa_df[\"msa_rent_adj\"], \n",
    "              box_visible=True,\n",
    "              meanline_visible=True\n",
    "             ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Median Household Income\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Median Monthly Rent \", row=1, col=2)\n",
    "fig.update_layout(title_text=\"Household Income vs. Monthly Rent Over Time for MSA Adjusted for Inflation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puma_df[\"puma_income_adj\"] = puma_df.apply(lambda row: \n",
    "            (row[\"puma_income\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "puma_df[\"puma_rent_adj\"] = puma_df.apply(lambda row: \n",
    "            (row[\"puma_rent\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"puma_income_adj\"] = scard_df.apply(lambda row: \n",
    "            (row[\"puma_income\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"puma_rent_adj\"] = scard_df.apply(lambda row: \n",
    "            (row[\"puma_rent\"]/cpi_df.at[row[\"year\"]]) * 100,\n",
    "        axis=1\n",
    ")\n",
    "scard_df[\"puma_rent_adj_ytd\"] = scard_df.apply(lambda row: \n",
    "            (row[\"puma_rent\"]/cpi_df.at[row[\"year\"]]) * 100 * 12,\n",
    "        axis=1\n",
    ")\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.add_trace(\n",
    "    go.Violin(x=puma_df[\"year\"], \n",
    "              y=puma_df[\"puma_income_adj\"], \n",
    "              box_visible=True,\n",
    "              meanline_visible=True\n",
    "             ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Violin(x=puma_df[\"year\"], \n",
    "              y=puma_df[\"puma_rent_adj\"], \n",
    "              box_visible=True,\n",
    "              meanline_visible=True\n",
    "             ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Median Household Income\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Median Monthly Rent\", row=1, col=2)\n",
    "fig.update_layout(title_text=\"Household Income vs. Monthly Rent Over Time for PUMA Adjusted for Inflation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(scard_df, x=\"net_cost_adjusted\", y=\"msa_rent_adj_ytd\", trendline=\"ols\", facet_col=\"ownership\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(scard_df, x=\"ownership\", y=\"puma_rent_adj_ytd\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(scard_df, x=\"region\", y=\"puma_rent_adj_ytd\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(scard_df, x=\"locale\", y=\"puma_rent_adj_ytd\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Analysis, Hypothesis Testing, and Machine Learning** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since monthly rent appears to increase linearly proportionately to household income, I will be using a Least Squares Linear Regression to highlight this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_df[\"locale\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(msa_df, x=\"msa_rent_adj\", y=\"msa_income_adj\", trendline=\"ols\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = px.get_trendline_results(fig)\n",
    "print(results.px_fit_results.iloc[0].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(puma_df, x=\"puma_rent_adj\", y=\"puma_income_adj\", trendline=\"ols\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = px.get_trendline_results(fig)\n",
    "print(results.px_fit_results.iloc[0].summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by the OLS Regression Summary, the MSA plot has a much more accurate regression with an R-squared of 0.814 compared to PUMA's 0.721, but this can be explained by PUMA having significantly more data points (PUMAs are more specific than MSAs) and the variance among the data is significantly wider (For example, the monthly rent for MSA does not even exceed 1000, but the montly rent for PUMA goes well above 1100). This, as well as many other factors, shows a strong tendency for universities to affect pricing much more on a small scale, such as a city level, than a county or metropolitan-center-wide scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puma_rent_model = smf.ols(formula=\"puma_rent_adj ~ year * ownership + in_tuition_adjusted\", data=scard_df)\n",
    "puma_rent_res = puma_rent_model.fit()\n",
    "\n",
    "msa_rent_model = smf.ols(formula=\"msa_rent_adj ~ year * ownership + in_tuition_adjusted\", data=scard_df)\n",
    "msa_rent_res = msa_rent_model.fit()\n",
    "\n",
    "prm2 = smf.ols(formula=\"puma_rent_adj ~ year * ownership\", data=scard_df)\n",
    "prm2_res = prm2.fit()\n",
    "\n",
    "num = len(scard_df[\"year\"].values)\n",
    "df_samples = scard_df[[\"year\", \"ownership\", \"in_tuition_adjusted\"]]\n",
    "df_samples = sm.add_constant(df_samples)\n",
    "sample_set = np.column_stack(\n",
    "    (\n",
    "        np.ones(num), \n",
    "        scard_df[\"year\"].values, \n",
    "        scard_df[\"ownership\"].values,\n",
    "        scard_df[\"in_tuition_adjusted\"].values,\n",
    "    )\n",
    ")\n",
    "\n",
    "df_samples2 = scard_df[[\"year\", \"ownership\"]]\n",
    "df_samples2 = sm.add_constant(df_samples)\n",
    "sample_set2 = np.column_stack(\n",
    "    (\n",
    "        np.ones(num), \n",
    "        scard_df[\"year\"].values, \n",
    "        scard_df[\"ownership\"].values,\n",
    "    )\n",
    ")\n",
    "scard_df[\"puma_rent_fit\"] = puma_rent_res.predict(df_samples)\n",
    "scard_df[\"puma_rent_fit2\"] = prm2_res.predict(df_samples)\n",
    "scard_df[\"msa_rent_fit\"] = msa_rent_res.predict(df_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "fig.update_layout(height=800, width=800, title_text=\"Interaction Model Public Use MicroData Area Rent Distribution and Trend Lines\")\n",
    "for i,id in enumerate (scard_df[\"ownership\"].unique()):\n",
    "    sub_df = scard_df[scard_df[\"ownership\"] == id].copy().sort_values(by=\"year\")\n",
    "\n",
    "    trend_df = sub_df.groupby(\"year\")[\"puma_rent_fit\"].mean()\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            x=sub_df['year'], \n",
    "            y=sub_df['puma_rent_adj'],\n",
    "            name=id,\n",
    "        ),\n",
    "        row=(i+1), col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=trend_df.index, \n",
    "            y=trend_df,\n",
    "            name=id,\n",
    "        ),\n",
    "        row=(i+1), col=1\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "fig.update_layout(height=800, width=800, title_text=\"Interaction Model Metropolitan Statistical Area Rent Distribution and Trend Lines\")\n",
    "for i,id in enumerate (scard_df[\"ownership\"].unique()):\n",
    "    sub_df = scard_df[scard_df[\"ownership\"] == id].copy().sort_values(by=\"year\")\n",
    "\n",
    "    trend_df = sub_df.groupby(\"year\")[\"msa_rent_fit\"].mean()\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            x=sub_df['year'], \n",
    "            y=sub_df['msa_rent_adj'],\n",
    "            name=id,\n",
    "        ),\n",
    "        row=(i+1), col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=trend_df.index, \n",
    "            y=trend_df,\n",
    "            name=id,\n",
    "        ),\n",
    "        row=(i+1), col=1\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(puma_rent_res.summary())\n",
    "print(puma_rent_res.pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prm2_res.summary())\n",
    "print(prm2_res.pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msa_rent_res.summary())\n",
    "print(msa_rent_res.pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scard_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=7 color=#8D84B5 > </hr> \n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "## <font color = #6b4cde face=\"Verdana\"> **Insight and Policy Decision** </font>\n",
    "</center>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr size=7 color=#8D84B5 > </hr> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our observations throughout our project, we can conclude:\n",
    "1. There is a correlation between median income and median housing costs\n",
    "2. As time continues, both median income and median housing costs will likely continue rising due to inflation.\n",
    "3. Localities near universities are more volatile and are often significantly more expensive than the housing further out from them, creating a heavily gentrified environment (We can see an example of this in College Park)\n",
    "\n",
    "If you would like to learn more about the tools we used to make this:\n",
    "* [Census API](https://www.census.gov/data/developers/guidance/api-user-guide.Overview.html#list-tab-2080675447)\n",
    "* [USNews API](FILL IN)\n",
    "* [College Scorecard API](https://collegescorecard.ed.gov/data/documentation/)\n",
    "* [Zip To Tract API/Excel Doc](https://www.huduser.gov/portal/datasets/usps_crosswalk.html#data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
